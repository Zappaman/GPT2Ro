EXPERIMENT:
  OUTPUT_FOLDER: "./outputs_unfrozen"
  TENSORBOARD_FOLDER: "./run_unfrozen"
  RESUME_TRAINING_ON_RESTART: True
  NUM_DATALOADER_WORKERS: 8
DATASET:
  TRAIN_FILE: "data/corpus/train.txt"
  VALID_FILE: "data/corpus/val.txt"
  TOKENIZER_PREFIX_PATH: "data/gpt2_tokenizer_ro/gpt2_tokenizer_ro-"
TRAIN:
  GPT2_PRETRAINED_MODEL: 'gpt2'
  LAST_PRETRAINED_MODEL: ''
  SAVE_STEPS: 5000
  WEIGHT_DECAY: 0.001
  NUM_TRAIN_EPOCHS: 10
  LOG_EVERY: 1000
  EVAL_STEPS: 5000
  GRADIENT_ACCUMULATION_STEPS: 4
  LR_SCHEDULER_TYPE: "linear" # "linear", "cosine", "cosine_with_restarts", "polynomial", "constant", "constant_with_warmup"
  NUM_WARMUP_STEPS: 0
  BATCH_SIZE: 4
  USE_FP_16: True
  USE_GRADUAL_UNFREEZING: True
  UNFREEZING:
    UNFREEZE_GROUPS: [{'lm_head':'*', 'transformer':'*'}]
    TRAIN_STEPS_LIST: [1000000000000]
    LEARNING_RATE_LIST: [0.002]